{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from graphviz import Digraph\n",
    "from pprint import pprint\n",
    "from pulp import *\n",
    "from time import sleep\n",
    "import math\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(string):\n",
    "    try:\n",
    "        float(string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "t1=LOAD(x);\n",
    "t2=t1 +4;\n",
    "t3=t1 *8;\n",
    "t4=t1 -4;\n",
    "t5=t1 /2;\n",
    "t6=t2 * t3;\n",
    "t7=t4-t5;\n",
    "t8=t6 * t7;\n",
    "t9=t5 * t2;\n",
    "t10= ^ t9;\n",
    "STORE(y , t8 );\n",
    "STORE(z , t10 );\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "t1=LOAD(x);\n",
    "t2=t1 +4;\n",
    "t3= t1 * 8;\n",
    "t4=t3 /t2;\n",
    "STORE(y , t4 );\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "t1=LOAD(x);\n",
    "t2=t1 + t1;\n",
    "t1=t1 - 4;\n",
    "t2=t1 /t2;\n",
    "t1=t2 * t1;\n",
    "STORE(y , t1 );\n",
    "STORE(z , t2 );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "t1=LOAD(x);\n",
    "t1= ^t1;\n",
    "STORE(y , t1 );\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"\"\"\n",
    "t3=LOAD(x);\n",
    "t1=49;\n",
    "t2=40+40;\n",
    "t1=^t1;\n",
    "t2=t2/2;\n",
    "t1=t1*t2;\n",
    "t1=t1/t3;\n",
    "STORE(y , t1 );\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LOAD', 't3', 'x', ()), ('EQ', 't1', '49', ()), ('ADD', 't2', '40', '40', ()), ('SQRT', 't1', 't1', (1,)), ('DIV', 't2', 't2', '2', (2,)), ('MUL', 't1', 't1', 't2', (3, 4)), ('DIV', 't1', 't1', 't3', (0, 3, 5)), ('STORE', 'y', 't1', (6,))]\n",
      "[('LOAD', 't3', 'x', ()), ('SQRT', 't1', '49', ()), ('DIV', 't2', '80', '2', ()), ('MUL', 't1', 't1', 't2', (1, 2)), ('DIV', 't1', 't1', 't3', (0, 3)), ('STORE', 'y', 't1', (4,))]\n",
      "\n",
      "[('LOAD', 't3', 'x', ()), ('SQRT', 't1', '49', ()), ('DIV', 't2', '80', '2', ()), ('MUL', 't1', 't1', 't2', (1, 2)), ('DIV', 't1', 't1', 't3', (0, 3)), ('STORE', 'y', 't1', (4,))]\n",
      "[('LOAD', 't3', 'x', ()), ('MUL', 't1', '7.0', '40.0', ()), ('DIV', 't1', 't1', 't3', (0, 1)), ('STORE', 'y', 't1', (2,))]\n",
      "\n",
      "[('LOAD', 't3', 'x', ()), ('MUL', 't1', '7.0', '40.0', ()), ('DIV', 't1', 't1', 't3', (0, 1)), ('STORE', 'y', 't1', (2,))]\n",
      "[('LOAD', 't3', 'x', ()), ('DIV', 't1', '280.0', 't3', (0,)), ('STORE', 'y', 't1', (1,))]\n",
      "\n",
      "[('LOAD', 't3', 'x', ()), ('DIV', 't1', '280.0', 't3', (0,)), ('STORE', 'y', 't1', (1,))]\n",
      "[('LOAD', 't3', 'x', ()), ('DIV', 't1', '280.0', 't3', (0,)), ('STORE', 'y', 't1', (1,))]\n",
      "\n",
      "Final IR\n",
      "[('LOAD', 't3', 'x', ()),\n",
      " ('DIV', 't1', '280.0', 't3', (0,)),\n",
      " ('STORE', 'y', 't1', (1,))]\n",
      "ind ['t3', 't1', 'y']\n",
      "dep [[], ['t3'], ['t1']]\n",
      "line: [(), (0,), (1,)]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"167pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 166.59 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 162.59,-184 162.59,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.29\" cy=\"-162\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.29\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">0: t3=LOAD(x)</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.29\" cy=\"-90\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.29\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">1: t1=280.0/t3</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M79.29,-143.7C79.29,-135.98 79.29,-126.71 79.29,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.79,-118.1 79.29,-108.1 75.79,-118.1 82.79,-118.1\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"79.29\" cy=\"-18\" rx=\"79.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"79.29\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2: STORE(y,t1)</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M79.29,-71.7C79.29,-63.98 79.29,-54.71 79.29,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"82.79,-46.1 79.29,-36.1 75.79,-46.1 82.79,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7fd9506a3160>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parser():\n",
    "    def __init__(self) -> None:\n",
    "        self.operators = [\"*\",\"/\",\"+\",\"-\",\"^\"]\n",
    "        self.delims = [\" \", \"(\",\")\",\"=\"]\n",
    "        self.symbol_to_name = { \"+\": \"ADD\",\n",
    "                                \"-\": \"SUB\",\n",
    "                                \"*\": \"MUL\",\n",
    "                                \"/\": \"DIV\",\n",
    "                                \"^\": \"SQRT\" }\n",
    "        self.operator_map = {\n",
    "                'ADD': '+',\n",
    "                'SUB': '-',\n",
    "                'MUL': '*',\n",
    "                'DIV': '/',\n",
    "            }\n",
    "        self.dot = Digraph()\n",
    "    \n",
    "    def _gen_tokenized_list(self,instructions):\n",
    "        tokenized_list = []\n",
    "        for instr in instructions[:]:\n",
    "            tokens = []\n",
    "            cur = \"\"\n",
    "            pos = 0\n",
    "            while pos < len(instr):\n",
    "                if instr[pos] in self.delims or instr[pos] in self.operators:\n",
    "                    if cur != \"\":\n",
    "                        tokens.append(cur)\n",
    "                    if instr[pos] != \" \":\n",
    "                        tokens.append(instr[pos])\n",
    "                    cur = \"\"\n",
    "                else:\n",
    "                    cur += instr[pos]\n",
    "                pos += 1\n",
    "            if cur != \"\":\n",
    "                tokens.append(cur)\n",
    "            tokenized_list.append(tokens)\n",
    "        return tokenized_list\n",
    "\n",
    "    def _gen_IR(self, tokenized_list):\n",
    "        IR = []\n",
    "        for tokens in tokenized_list:\n",
    "            if \"LOAD\" in tokens:\n",
    "                IR.append((\"LOAD\",tokens[0],tokens[4]))\n",
    "            elif \"=\" in tokens:\n",
    "                if len(tokens) == 3:\n",
    "                    IR.append((\"EQ\",tokens[0],tokens[2]))\n",
    "                elif tokens[2] != \"^\":\n",
    "                    IR.append((self.symbol_to_name[tokens[3]],tokens[0],tokens[2],tokens[4]))\n",
    "                else:\n",
    "                    IR.append((self.symbol_to_name[tokens[2]],tokens[0],tokens[3]))\n",
    "            elif \"STORE\" in tokens:\n",
    "                IR.append((\"STORE\",tokens[2],tokens[4]))\n",
    "        \n",
    "        return IR \n",
    "\n",
    "    def _gen_dependencies(self,IR):\n",
    "        writes, reads = [], []\n",
    "        write_depend, edges = [], []\n",
    "        read_depend = []\n",
    "\n",
    "        for instr in IR:\n",
    "            depend_tokens = []\n",
    "            depend_tokens_pos = []\n",
    "            #Check Read Dependicies\n",
    "            #print(instr)\n",
    "            for token in  instr[2:]:\n",
    "                #print(token,instr[2:],indep)  \n",
    "                for pos, dep_token in reversed(list(enumerate(writes))):\n",
    "                    if token == dep_token:\n",
    "                        if token not in depend_tokens: \n",
    "                            depend_tokens.append(token)\n",
    "                            depend_tokens_pos.append(pos)\n",
    "                        break\n",
    "                    \n",
    "            #Check Write Dependicies\n",
    "            token = instr[1]\n",
    "            read_tokens = []\n",
    "            read_tokens_pos = []\n",
    "            for pos , tokens in  enumerate(reads):\n",
    "                if token in tokens:\n",
    "                    read_tokens.append(token)\n",
    "                    read_tokens_pos.append(pos)\n",
    "\n",
    "\n",
    "            read_depend.append(tuple(set(read_tokens_pos)))\n",
    "            writes.append('' if instr[1] == \"STORE\" else instr[1])\n",
    "  \n",
    "            reads.append(depend_tokens)\n",
    "            write_depend.append(tuple(set(depend_tokens_pos)))\n",
    "\n",
    "        for x, ys in enumerate(write_depend):\n",
    "            for y in ys:\n",
    "                edges.append((y,x))\n",
    "\n",
    "        for idx in range(len(IR)):\n",
    "            all_depend = tuple(set((write_depend[idx]+read_depend[idx])))\n",
    "            IR[idx] = IR[idx] +tuple((all_depend, ))\n",
    "        \n",
    "        return IR, writes, reads, edges, write_depend\n",
    "\n",
    "    def _dead_code_removal(self, IR, write_depend, instructions):\n",
    "        \n",
    "        instructions_keep = set()\n",
    "        store_instructions_pos = []\n",
    "        for idx, instrc in enumerate(IR):\n",
    "            if instrc[0] == \"STORE\":\n",
    "                store_instructions_pos.append(idx)\n",
    "        \n",
    "        def dfs(idx):\n",
    "    \n",
    "            if len(write_depend[idx]) ==0 or IR[idx][0] == \"LOAD\":\n",
    "                instructions_keep.add(idx)\n",
    "                return True\n",
    "            \n",
    "        \n",
    "            results = False\n",
    "            for pos in write_depend[idx]:\n",
    "                if dfs(pos):\n",
    "                    results = True or results\n",
    "\n",
    "            if results:\n",
    "                instructions_keep.add(idx)\n",
    "\n",
    "            return results\n",
    "\n",
    "        for instrc_idx in store_instructions_pos:\n",
    "            dfs(instrc_idx)\n",
    "\n",
    "        new_IR_Partial, new_instructions = [], []\n",
    "        for idx, instruction in enumerate(IR):\n",
    "            if idx in instructions_keep:\n",
    "                new_IR_Partial.append(instruction[:len(instruction)-1])\n",
    "                new_instructions.append(instructions[idx])\n",
    "\n",
    "        return new_instructions, new_IR_Partial\n",
    "\n",
    "    def _constant_folding(self,IR):\n",
    "        for idx, instruction in enumerate(IR):\n",
    "            #print(\"here\", instruction[0] in self.symbol_to_name)\n",
    "            if instruction[0] in self.symbol_to_name.values():\n",
    "                \n",
    "                if instruction[0] == \"SQRT\":\n",
    "                    if is_number(instruction[2]):\n",
    "                        IR[idx] = ('EQ', instruction[1], str(math.sqrt(float(instruction[2]))), instruction[3] )\n",
    "                        \n",
    "                else:\n",
    "                    \n",
    "                    if is_number(instruction[2]) and is_number(instruction[3]):\n",
    "                        result = eval(instruction[2]  +  self.operator_map[instruction[0]]  + instruction[3])\n",
    "                        IR[idx] = ('EQ', instruction[1], str(result), instruction[4] )\n",
    "                        \n",
    "\n",
    "        return IR \n",
    "\n",
    "    def _constant_propogation(self, IR, write_depend):\n",
    "        bool = False\n",
    "        for idx, instruction in enumerate(IR):\n",
    "\n",
    "            if instruction[0] == \"LOAD\":\n",
    "                continue\n",
    "\n",
    "            value1 = instruction[2]\n",
    "            value2 = instruction[3]\n",
    "            \n",
    "            for pos in write_depend[idx]:\n",
    "                if IR[pos][0] != \"EQ\":\n",
    "                    continue\n",
    "                constant = IR[pos][1]\n",
    "                value = IR[pos][2]\n",
    "\n",
    "                if instruction[2] == constant:\n",
    "                    value1 = value\n",
    "                    bool = True\n",
    "\n",
    "                if instruction[0] not in [\"STORE\",\"SQRT\"]:\n",
    "    \n",
    "                    if instruction[3] == constant:\n",
    "                        value2 = value\n",
    "                        bool = True\n",
    "\n",
    "            if len(IR[idx]) == 5:\n",
    "                IR[idx] = (instruction[0], instruction[1], value1, value2, instruction[4])\n",
    "            else:\n",
    "                IR[idx] = (instruction[0], instruction[1], value1, instruction[3])\n",
    "\n",
    "\n",
    "        new_partial_IR = []\n",
    "        for idx, instruction in enumerate(IR):\n",
    "            if instruction[0] != \"EQ\":\n",
    "                if len(instruction) == 5:\n",
    "                    x = (instruction[0],instruction[1],instruction[2],instruction[3])\n",
    "                else:\n",
    "                    x = (instruction[0],instruction[1],instruction[2])\n",
    "                new_partial_IR.append(x)\n",
    "        \n",
    "        return  new_partial_IR, bool\n",
    "\n",
    "    def _IR_to_instruction(self, IR):\n",
    "        instructions = []\n",
    "        for instruction in IR:\n",
    "            if instruction[0] == \"LOAD\":\n",
    "                name = f'{instruction[1]}=LOAD({instruction[2]})'\n",
    "            elif instruction[0] == \"STORE\":\n",
    "                name = f'STORE({instruction[1]},{instruction[2]})'\n",
    "            elif instruction[0] == \"EQ\": \n",
    "                name = f'{instruction[1]}={instruction[2]}'\n",
    "            elif instruction[0] in self.operator_map: \n",
    "                name = f'{instruction[1]}={instruction[2]}{self.operator_map[instruction[0]]}{instruction[3]}'\n",
    "            elif instruction[0] in \"SQRT\": \n",
    "                name = f'{instruction[1]}=^{instruction[2]}'\n",
    "            instructions.append(name)\n",
    "        return instructions\n",
    "\n",
    "    def _dfg(self,instructions,edges):\n",
    "        file_contents = \"\"\n",
    "        for idx, instr in enumerate(instructions):\n",
    "            self.dot.node(str(idx), str(idx)+\": \"+str(instr))\n",
    "            file_contents += f\"{idx}: {instr}\\n\"\n",
    "\n",
    "        for x,y in edges:\n",
    "            self.dot.edge(str(x),str(y))\n",
    "            file_contents += f\"{x}->{y}\\n\"\n",
    "        \n",
    "        with open(\"DFG.output\", \"w\") as f:\n",
    "            f.write(file_contents)\n",
    "    \n",
    "    def parse(self,code):\n",
    "    \n",
    "        instructions = [instr.strip(\"\\n\") for instr in code.split(\";\")[:-1]]\n",
    "\n",
    "\n",
    "        #Tokenize instruction set\n",
    "        tokenized_list = self._gen_tokenized_list(instructions)\n",
    "\n",
    "\n",
    "        #Generates IR without dependency list\n",
    "        IR_partial = self._gen_IR(tokenized_list)\n",
    "        \n",
    "        #Generates IR(with dependencies list)\n",
    "        IR, writes, depend, edges, write_depend = self._gen_dependencies(IR_partial)\n",
    "        \n",
    "        #Handles WAW and insutrctions that have no dependecies\n",
    "        instructions, IR_partial = self._dead_code_removal(IR, write_depend, instructions)\n",
    "\n",
    "        #Regenerate New IR with update instruction list\n",
    "        IR, writes, depend, edges, write_depend = self._gen_dependencies(IR_partial)\n",
    "        \n",
    "\n",
    "\n",
    "        #Constant Folding then Propgation Loop. \n",
    "        #Evaluates constant expressions and Replaces variables with constants.\n",
    "        constant_folding_bool = True\n",
    "        while(constant_folding_bool):\n",
    "            #Constant Folding\n",
    "            print(IR)\n",
    "            IR = self._constant_folding(IR)\n",
    "            \n",
    "            #Constant Propogation\n",
    "            IR_partial, constant_folding_bool = self._constant_propogation(IR, write_depend)\n",
    "\n",
    "            #Regenerate New IR with update instruction list\n",
    "            IR, writes, depend, edges, write_depend = self._gen_dependencies(IR_partial)\n",
    "            print(IR)\n",
    "            print()\n",
    "\n",
    "        instructions = self._IR_to_instruction(IR)\n",
    "\n",
    "        #Generate DFG output and image\n",
    "        self._dfg(instructions,edges)\n",
    "        \n",
    "        return IR, depend, writes, write_depend\n",
    "\n",
    "parse_instance = Parser()\n",
    "IR,depend,indep,line_depend= parse_instance.parse(sample)\n",
    "print('Final IR')\n",
    "pprint(IR)\n",
    "print(\"ind\",indep)\n",
    "print(\"dep\",depend)\n",
    "print(\"line:\",line_depend)\n",
    "\n",
    "parse_instance.dot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\t New Imbalance: 1, Current Imbalance: 1\n",
      "Stopping with an Current Imbalance of 1\n",
      "Iteration: 0\t New Imbalance: 0, Current Imbalance: 0\n",
      "Stopping with an Current Imbalance of 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CodeGen():\n",
    "    def __init__(self,num_PEs,path=\"/\") -> None:\n",
    "        self.file_path = path\n",
    "        self.num_PEs = num_PEs\n",
    "        with open('operation_latency.json', 'r') as f:\n",
    "            self.cycle_times = json.load(f)\n",
    "    \n",
    "    def generate_backend_code(self,IR):\n",
    "        # Step 2: Receive IR, number of PEs, and cycle times\n",
    "\n",
    "        # Step 3: Assign initial tasks to PEs\n",
    "        assignments = self.initial_assignment(IR)\n",
    "        \n",
    "        #Step 4:\n",
    "        execution_times = self.calculate_execution_times(assignments)\n",
    "\n",
    "        # Step 5: Check workload imbalance\n",
    "        max_execution_time = max(execution_times)\n",
    "        min_execution_time = min(execution_times)\n",
    "        cur_imbalance = max_execution_time - min_execution_time\n",
    "\n",
    "\n",
    "      \n",
    "        iteration = 0\n",
    "\n",
    "        #Repeat 4-6\n",
    "        while True:\n",
    "            \n",
    "            \n",
    "            # Step 6: Task migration or swapping strategy\n",
    "            new_assignments = self.rebalance_workload(assignments, execution_times)\n",
    "\n",
    "            # Step 4: Calculate execution cost for each PE\n",
    "            execution_times = self.calculate_execution_times(new_assignments)\n",
    "\n",
    "            # Step 5: Check workload imbalance\n",
    "            max_execution_time = max(execution_times)\n",
    "            min_execution_time = min(execution_times)\n",
    "            new_imbalance = max_execution_time - min_execution_time\n",
    "\n",
    "            print(f\"Iteration: {iteration}\\t New Imbalance: {new_imbalance}, Current Imbalance: {cur_imbalance}\")\n",
    "            if new_imbalance >= cur_imbalance or cur_imbalance==0:\n",
    "                print(f\"Stopping with an Current Imbalance of {cur_imbalance}\")\n",
    "                \n",
    "                break  # Terminate if workload is balanced within threshold or maximum iterations reached\n",
    "            cur_imbalance = new_imbalance\n",
    "            assignments = new_assignments\n",
    "            \n",
    "            iteration += 1 \n",
    "        synced_tasks = self.sync(assignments, IR)\n",
    "        for pe_id, assigned_tasks in enumerate(synced_tasks):\n",
    "            # Step 8: Generate output code for each PE\n",
    "            code = self.generate_code(assigned_tasks)\n",
    "\n",
    "            # Step 9: Dump output code to files\n",
    "            self.dump_code_to_file(code, pe_id)\n",
    "\n",
    "    def initial_assignment(self,tasks):\n",
    "        # Assign initial tasks to PEs\n",
    "        \n",
    "        assignments = [[] for _ in range(self.num_PEs)]\n",
    "        task_index = 0\n",
    "\n",
    "        for task in tasks:\n",
    "            pe_id = task_index % self.num_PEs\n",
    "            assignments[pe_id].append(task)\n",
    "            task_index += 1\n",
    "\n",
    "        \n",
    "        return assignments\n",
    "\n",
    "    def calculate_execution_times(self,assignments):\n",
    "        # Calculate execution time for each PE\n",
    "        execution_times = []\n",
    "\n",
    "        for assigned_tasks in assignments:\n",
    "            execution_time = 0\n",
    "            for task in assigned_tasks:\n",
    "                if task:\n",
    "                    task_name = task[0]\n",
    "                    if task_name in self.cycle_times:\n",
    "                        execution_time += self.cycle_times[task_name]\n",
    "            execution_times.append(execution_time)\n",
    "\n",
    "        return execution_times\n",
    "\n",
    "    def rebalance_workload(self,assignments, execution_times):\n",
    "\n",
    "        new_assignments = copy.deepcopy(assignments)\n",
    "        \n",
    "        # Perform task migration or swapping to balance workload\n",
    "        max_index = execution_times.index(max(execution_times))\n",
    "        min_index = execution_times.index(min(execution_times))\n",
    "\n",
    "        # Swap a task from the most loaded PE to the least loaded PE\n",
    "        task_to_swap = new_assignments[max_index].pop(0)\n",
    "        new_assignments[min_index].append(task_to_swap)\n",
    "\n",
    "        return new_assignments\n",
    "\n",
    "    def sync(self,assignments, IR):\n",
    "\n",
    "        sync_code = [[] for _ in range(len(assignments))]\n",
    "        hash = {}\n",
    "        instruction_cycle_times = [self.cycle_times[task[0]] for task in IR]\n",
    "        for pos, instruc in enumerate(IR):\n",
    "            hash[instruc] = pos\n",
    "            \n",
    "\n",
    "        live_time = [0 for _ in range(len(assignments)) ]\n",
    "        current_instruction = [\"NOP\"for _ in range(len(assignments)) ]\n",
    "        numerical_assignment = [[(hash[task],task[-1]) for task in tasks] for tasks in assignments ]\n",
    "\n",
    "        instructions_done = set()\n",
    "        instructions_done.add(None)\n",
    "        cycle = 1\n",
    "        while len(IR) != len(instructions_done)-1:\n",
    "\n",
    "            for idx, (current, count) in enumerate(zip(current_instruction,live_time)):\n",
    "                #print(idx, current, count)\n",
    "                if current != \"NOP\":\n",
    "                    if count <= 1:\n",
    "                        instructions_done.add(current)\n",
    "                        current_instruction[idx] = \"NOP\"\n",
    "                    live_time[idx] -= 1\n",
    "\n",
    "            for assignment_id, tasks in enumerate(numerical_assignment):\n",
    "                \n",
    "                if current_instruction[assignment_id] == \"NOP\":\n",
    "                    for task in tasks:\n",
    "                        #print(assignment_id, task, type(task[1]), task[0] not in instructions_done and task[1] in instructions_done)\n",
    "                        if task[0] not in instructions_done and all(num in instructions_done for num in task[1]):\n",
    "                            #print(\"Added \",task[0])\n",
    "                            current_instruction[assignment_id] = task[0]  \n",
    "                            live_time[assignment_id] = instruction_cycle_times[task[0]]\n",
    "                            sync_code[assignment_id].append(IR[task[0]])\n",
    "                            break\n",
    "\n",
    "                if current_instruction[assignment_id] == \"NOP\" and len(IR) != len(instructions_done)-1:\n",
    "                    sync_code[assignment_id].append(\"NOP\")\n",
    "\n",
    "            \"\"\" print(f'Cycle {cycle}')\n",
    "            print(instructions_done)\n",
    "            print(current_instruction)\n",
    "            print(live_time)\n",
    "            print() \"\"\"\n",
    "\n",
    "            cycle += 1\n",
    "            #sleep(1)\n",
    "        #pprint(sync_code)\n",
    "        return  sync_code \n",
    "            \n",
    "    def generate_code(self,tasks):\n",
    "        # Generate output code for a given set of tasks\n",
    "        code = \"\"\n",
    "        self.cycle_times['N'] = 1\n",
    "        #print(\"final tasks:\",tasks)\n",
    "        for task in tasks:\n",
    "            if task:\n",
    "                #print(task)\n",
    "                for idx in range(self.cycle_times[task[0]]):\n",
    "                        task_formated = str(task[:len(task)-1]).strip(\"()\").replace(\"'\", \"\") if task != \"NOP\" else task\n",
    "                        code += (task_formated + \"\\n\")  if idx == 0 else \"\\n\"\n",
    "\n",
    "        return code\n",
    "\n",
    "    def dump_code_to_file(self,code, pe_id):\n",
    "        # Dump generated code to a file for a specific PE\n",
    "        filename = f\"{self.file_path}PE_{pe_id}_code.txt\"\n",
    "\n",
    "        with open(filename, \"w\") as file:\n",
    "            file.write(code)\n",
    "\n",
    "multi_core_count = 3   \n",
    "\n",
    "multi_code_gen_instance = CodeGen(multi_core_count,path=\"multi-core_code/\")\n",
    "multi_code_gen_instance.generate_backend_code(IR)\n",
    "\n",
    "single_code_gen_instance = CodeGen(1,path=\"single-core_code/\")\n",
    "single_code_gen_instance.generate_backend_code(IR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "[[['STORE', 'y', '1.7320508075688772']], [['NOP']], [['NOP']]]\n",
      "1.7320508075688772 True\n",
      "Cycle:1,\tPE_0: STORE, y, 1.7320508075688772[1], \tPE_1: NOP[1], \tPE_2: NOP[1], \n",
      "{'x': 10, 'y': 1.7320508075688772}\n"
     ]
    }
   ],
   "source": [
    "class Simulator():\n",
    "    def __init__(self, pes, file_path) -> None:\n",
    "        self.MEM = {}\n",
    "        self.RG = {}\n",
    "        self.pe_count = pes\n",
    "        self.file_path = file_path\n",
    "        with open('operation_latency.json', 'r') as f:\n",
    "            self.cycle_times = json.load(f)\n",
    "        self.cycle_times['NOP'] = 1\n",
    "    \n",
    "    def load_files(self):\n",
    "        code = []\n",
    "        for pe in range(self.pe_count):\n",
    "            file_name = f'PE_{pe}_code.txt'\n",
    "            with open(self.file_path+file_name) as f:\n",
    "                data = f.read()\n",
    "            code.append([[j.replace(\" \",'') for j in i.split(\",\")]for i in data.split(\"\\n\") if i])\n",
    "        print(code)\n",
    "        return code\n",
    "\n",
    "    def run(self):\n",
    "        code = self.load_files()\n",
    "        instruction_running = [\"NOP\"]*self.pe_count\n",
    "        live_cycles = [0]*self.pe_count\n",
    "        instruction_pos = [0]*self.pe_count\n",
    "        cycle = 1\n",
    "        while all((instruction_pos[pe] < len(code[pe])) for pe in range(self.pe_count)):\n",
    "            \n",
    "            for pe in range(self.pe_count):\n",
    "\n",
    "                pos = instruction_pos[pe]\n",
    "                if pos >= len(code[pe]):\n",
    "                    continue\n",
    "\n",
    "                #Cycle over. Update with New instruction\n",
    "                if live_cycles[pe] == 0:\n",
    "                    instruction_running[pe] = code[pe][pos]\n",
    "                    live_cycles[pe] = self.cycle_times[instruction_running[pe][0]]\n",
    "                    instruction_pos[pe] += 1\n",
    "                    self.execute(instruction_running[pe])\n",
    "            \n",
    "            \n",
    "            #sleep(1)\n",
    "            message = \"\"\n",
    "            message += f'Cycle:{cycle},'\n",
    "            for pe in range(self.pe_count):\n",
    "                message += f\"\\tPE_{pe}: {', '.join(instruction_running[pe])}[{live_cycles[pe]}], \"\n",
    "            #message += f'\\n\\t\\tRG:{self.RG}  \\tMEM:{self.MEM}'\n",
    "            print(message)\n",
    "\n",
    "            #Update cycle times\n",
    "            for pe in range(self.pe_count):\n",
    "                live_cycles[pe] -= 1\n",
    "\n",
    "            #print(cycle,instruction_running,live_cycles,instruction_pos)\n",
    "            cycle += 1\n",
    " \n",
    "    def execute(self, instruction):\n",
    "        instruction_name = instruction[0]\n",
    "        \n",
    "        if instruction_name == \"LOAD\":\n",
    "            if instruction[2] not in self.MEM:\n",
    "                raise(ValueError(f'{instruction[2]} is not in Memory'))\n",
    "            self.RG[instruction[1]] = self.MEM[instruction[2]]\n",
    "            \n",
    "        elif instruction_name == \"STORE\":\n",
    "            print(instruction[2], is_number(instruction[2]))\n",
    "            if instruction[2] not in self.RG and not is_number(instruction[2]):\n",
    "                raise(ValueError(f'{instruction[2]} is not in Register Files'))\n",
    "            self.MEM[instruction[1]] = self.RG[instruction[2]] if not is_number(instruction[2]) else float(instruction[2])\n",
    "        \n",
    "        elif instruction_name in [\"ADD\",\"SUB\", \"MUL\", \"DIV\", \"SQRT\"]:\n",
    "            operator_map = {\n",
    "                'ADD': '+',\n",
    "                'SUB': '-',\n",
    "                'MUL': '*',\n",
    "                'DIV': '/',\n",
    "            }\n",
    "            x =  self.RG[instruction[2]] if instruction[2][0] == 't' else instruction[2]\n",
    "            if instruction_name != 'SQRT':\n",
    "                y =  self.RG[instruction[3]] if instruction[3][0] == 't' else instruction[3]\n",
    "                expression =  str(x)  +  operator_map[instruction_name]  + str(y)\n",
    "                self.RG[instruction[1]] = eval(expression)\n",
    "            else:\n",
    "                self.RG[instruction[1]] = math.sqrt(float(x))\n",
    "\n",
    "        elif instruction_name == \"NOP\":\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            raise(ValueError(f'Unknown Instruction: {instruction}'))\n",
    "        \n",
    "        #print(self.MEM, self.RG)\n",
    "\n",
    "multi_instance = Simulator(multi_core_count,'multi-core_code/')\n",
    "multi_instance.MEM['x']= 10\n",
    "print(multi_instance.MEM)\n",
    "multi_instance.run()\n",
    "print(multi_instance.MEM)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 10}\n",
      "[[['STORE', 'y', '1.7320508075688772']]]\n",
      "1.7320508075688772 True\n",
      "Cycle:1,\tPE_0: STORE, y, 1.7320508075688772[1], \n",
      "{'x': 10, 'y': 1.7320508075688772}\n"
     ]
    }
   ],
   "source": [
    "seq_instance = Simulator(1,'single-core_code/')\n",
    "seq_instance.MEM['x']= 10\n",
    "print(seq_instance.MEM)\n",
    "seq_instance.run()\n",
    "print(seq_instance.MEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_instance.MEM == multi_instance.MEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"1245\"\n",
    "x.isnumeric()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
